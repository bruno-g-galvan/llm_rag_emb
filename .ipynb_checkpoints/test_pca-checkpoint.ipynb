{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e5459a0-46b5-4e08-a1d2-14388e263027",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b16112-fc2c-4fc8-9b3d-0c1b166af185",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain\n",
    "#!pip install chromadb\n",
    "!pip install -U langchain-chroma\n",
    "!pip install pypdf\n",
    "!pip install pytest\n",
    "!pip install ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77731bea-18d8-4689-8887-5d255c288f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import shutil\n",
    "from langchain.document_loaders.pdf import PyPDFDirectoryLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain.schema.document import Document\n",
    "from langchain.vectorstores.chroma import Chroma\n",
    "import time\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "from langchain_chroma import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31cbde4d-33a6-46d4-b533-45cde430a1f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "entry 27 in Xref table invalid but object found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Neuron, Vol. 36, 585–596, November 14, 2002, Copyright 2002 by Cell Press\n",
      "The Unfolded Protein Response Modulates\n",
      "Disease Severity in Pelizaeus-Merzbacher Disease\n",
      "an X-linked recessive pediatric disorder characterized\n",
      "by three common genetic forms of disease: coding re-gion or splice site mutations, duplications of the wild-Cherie M. Southwood,\n",
      "1James Garbern,1,3\n",
      "Wei Jiang,1and Alexander Gow1,2,3,4\n",
      "1Center for Molecular Medicine and Genetics\n",
      "type PLP1 gene, and null alleles. These mutations yield2Department of Pediatrics\n",
      "a broad spectrum of disease phenotypes from severe,3Department of Neurology\n",
      "connatal disease to mild forms characterized by pure Wayne State University School of Medicine\n",
      "spastic paraparesis (reviewed in Garbern et al., 1999; Detroit, Michigan 48201\n",
      "Southwood and Gow, 2001). Mutant alleles that model\n",
      "all three of these genetic forms of PMD are available inmice, including (1) myelin synthesis-deficient (msd), an Summary\n",
      "A242V missense mutation causing severe disease, also\n",
      "identified in patients (Gencic and Hudson, 1990; Yama- The unfolded protein response (UPR) is a eukaryotic\n",
      "moto et al., 1998) and rumpshaker (rsh), an I186T mis- signaling pathway linking protein flux through the en-\n",
      "sense mutation causing mild disease, also found in pa- doplasmic reticulum to transcription and translational\n",
      "tients (Kobayashi et al., 1994; Schneider et al., 1992); repression. Herein, we demonstrate UPR activation\n",
      "(2)4e-Plp , comprising supernumerary copies of a 40 kb in the leukodystrophy Pelizaeus-Merzbacher disease\n",
      "wild-type Plp1 transgene causing overexpression (Ka- (PMD) as well as in three mouse models of this disease\n",
      "gawa et al., 1994); and (3) Plp1 null (Klugmann et al., and transfected fibroblasts expressing mutant protein.\n",
      "1997; Rosenbluth et al., 1996; Stecca et al., 2000). Dis- The CHOP protein, widely known as a proapoptotic\n",
      "ease in msd mice is apparent by 12 days postnatal (P12) transcription factor, modulates pathogenesis in the\n",
      "as moderate tremors, which rapidly progress through mouse models of PMD; however, this protein exhibits\n",
      "severe tremors to seizures causing death by 3–4 weeks. antiapoptotic activity. Together, these data show that\n",
      "On the other hand, rshmice develop symptoms by P14– the UPR has the potential to modulate disease severity\n",
      "16, exhibit moderate tremors and ataxia, but rarely ex- in many cells expressing mutant secretory pathway\n",
      "hibit seizures and have a normal life span (Fanarraga et proteins. Thus, PMD represents the first member of\n",
      "al., 1992; Griffiths et al., 1990). Disease severity caused a novel class of disparate degenerative diseases for\n",
      "byPLP1 gene duplication is proportional to the degreewhich UPR activation and signaling is the common\n",
      "of overexpression (Ikenaka and Kagawa, 1995), and nullpathogenic mechanism.\n",
      "alleles cause mild disease.\n",
      "Molecular mechanisms underlying the phenotypes ofIntroduction\n",
      "most PLP1 mutations are virtually unknown. Morpholog-\n",
      "ical analyses of oligodendrocytes from animal modelsOf the myriad physiological processes ongoing in all\n",
      "indicate that distinct cellular defects underlie pathogen-living organisms, few are more important to survival atesis of different genetic forms of PMD. For example,the levels of the cell and the organism than adaptationseveral missense mutations perturb endoplasmic reticu-to stress. Primordial lifeforms contended with everlum ultrastructure (Duncan, 1990); PLP1 overexpressionchanging environmental conditions by rapid changes atcauses swelling of the Golgi apparatus and aberrantthe transcriptional and posttranscriptional levels, andcholesterol trafficking (Kagawa et al., 1994; Readheadsince that time, virtually all species have retained andet al., 1994; Simons et al., 2002); and null alleles causeexpanded such rudimentary signaling cascades to sus-axonal abnormalities with late Wallerian degenerationtain life under adverse conditions. The unfolded proteinand oligodendrocyte loss (Griffiths et al., 1998; Steccaresponse (UPR) is a stress-induced signaling cascadeet al., 2000).in eukaryotes, and recent appreciation of its importanceHerein, we investigate involvement of the UPR inas a central regulatory circuit in the secretory pathwaypathogenesis arising from PLP1 coding region muta-has prompted broad interest in consequences to cellstions and demonstrate that several mutations activateshould the UPR be disrupted or overwhelmed (Traversthis signaling cascade. CHOP is induced in and localizedet al., 2000). Indeed, correlative evidence implicates theto the nuclei of transfected fibroblasts expressing mu-UPR in a number of genetic diseases (Aridor and Balch,tant PLP1, cultured oligodendrocytes from msd mice,1999). For example, mutations in the PRESENILIN geneand oligodendrocytes from rshandmsd mice express-\n",
      "from familial Alzheimer patients cause abnormal IRE1ing mutant Plp1 gene products in vivo. Moreover, we\n",
      "processing (Katayama et al., 1999; Niwa et al., 1999).show by Northern blotting and immunocytochemistry\n",
      "In this instance, the molecular defect alone does notthat CHOP is induced in oligodendrocytes from a PMD\n",
      "compromise UPR induction (Sato et al., 2000) but, con-patient harboring a splice site mutation that excludes\n",
      "ceivably, may sensitize neurons to other insults.exon 6 from PLP1 gene products. Finally, we directly\n",
      "We have investigated molecular pathogenesis of the demonstrate that CHOP modulates disease severity in\n",
      "leukodystrophy Pelizaeus-Merzbacher disease (PMD), rshmice and normally serves to protect oligodendro-\n",
      "a neurodegenerative disease causing diffuse hypomy- cytes from apoptosis. Together, these data provide\n",
      "elination of the central nervous system (CNS). PMD is compelling evidence that the UPR is relevant to patho-\n",
      "genesis in PMD, thereby attesting to the importanceof this regulatory pathway in disease. More broadly,\n",
      "4Correspondence: agow@genetics.wayne.edu' metadata={'source': 'documents/PIIS0896627302010450.pdf', 'page': 0}\n"
     ]
    }
   ],
   "source": [
    "# Load all the PDF documents from the \"documents\" folder\n",
    "document_loader = PyPDFDirectoryLoader(\"documents\")\n",
    "documents = document_loader.load()\n",
    "print(documents[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8e5fa14-bd5d-4c32-abc4-67d4ac5c3e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divides documents into chunks of size 1800 characters with 250 character overlap\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1800,\n",
    "    chunk_overlap=250,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "# Split the documents into smaller chunks for better processing\n",
    "chunks = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "347dd814-3891-4f95-a9f5-dd3aa2feed62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Ollama LLM embedding model with llama3 for generating vector embeddings\n",
    "ollama_emb = OllamaEmbeddings(model=\"llama3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bde3bb05-370f-4422-a224-7bbf1700d569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize ChromaDB for storing and retrieving embeddings\n",
    "CHROMA_PATH = \"chroma\" # Directory where Chroma will persist the embeddings\n",
    "db = Chroma(persist_directory=CHROMA_PATH, embedding_function=ollama_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0cd8823-f069-4649-b091-e321bd4d2af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Optional) PCA could be applied to reduce embedding dimensionality\n",
    "#def apply_pca(embeddings, n_components=50):\n",
    "#    pca = PCA(n_components=n_components)\n",
    "#    reduced_embeddings = pca.fit_transform(embeddings)\n",
    "#    return reduced_embeddings\n",
    "\n",
    "# Variables to track last page ID and chunk index for metadata\n",
    "last_page_id = None\n",
    "current_chunk_index = 0\n",
    "chunk_texts = []  # Store the text of chunks\n",
    "chunk_metadata = []  # Store metadata to later add to ChromaDB\n",
    "\n",
    "# Iterate through each chunk to generate metadata (like source, page, and ID)\n",
    "for chunk in chunks:\n",
    "    source = chunk.metadata.get(\"source\") # Document source (file path)\n",
    "    page = chunk.metadata.get(\"page\") # Page number in the document\n",
    "    current_page_id = f\"{source}:{page}\" # Create a unique page ID\n",
    "\n",
    "    # If the page is the same as the last one, increment the chunk index (for multiple chunks from one page)\n",
    "    if current_page_id == last_page_id:\n",
    "        current_chunk_index += 1\n",
    "    else:\n",
    "        current_chunk_index = 0 # Reset index if it's a new page\n",
    "\n",
    "    # Create a unique chunk ID using page ID and chunk index\n",
    "    chunk_id = f\"{current_page_id}:{current_chunk_index}\"\n",
    "    last_page_id = current_page_id # Update last seen page ID\n",
    "\n",
    "    # Add metadata (chunk ID) to the chunk and store for later\n",
    "    chunk.metadata[\"id\"] = chunk_id\n",
    "    chunk_metadata.append(chunk.metadata)\n",
    "    chunk_texts.append(chunk.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bdd4949-3397-459d-9371-01100f6aa411",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏱️ Tiempo tomado para embeber los chunks en lotes: 491.43 segundos\n"
     ]
    }
   ],
   "source": [
    "# Define the batch size for embedding chunks in smaller groups to optimize performance\n",
    "batch_size = 1000  # This can be adjusted based on system resources\n",
    "\n",
    "# Start measuring time for embedding process\n",
    "start_time = time.time()\n",
    "\n",
    "# Helper function to split chunk_texts into batches\n",
    "def create_batches(chunk_texts, batch_size):\n",
    "    for i in range(0, len(chunk_texts), batch_size):\n",
    "        yield chunk_texts[i:i + batch_size] # Yield batches of size batch_size\n",
    "\n",
    "# Initialize list to store all embeddings\n",
    "all_embeddings = []\n",
    "\n",
    "# Process each batch of text chunks to create embeddings\n",
    "for batch in create_batches(chunk_texts, batch_size):\n",
    "    # Use the Ollama embedding model to embed the current batch of text\n",
    "    batch_embeddings = ollama_emb.embed_documents(batch)\n",
    "    all_embeddings.extend(batch_embeddings) # Add the embeddings to the list\n",
    "\n",
    "# End time measurement for embedding process\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate and print the time taken to embed all chunks\n",
    "time_taken = end_time - start_time\n",
    "print(f\"⏱️ Tiempo tomado para embeber los chunks en lotes: {time_taken:.2f} segundos\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fcac3342-2906-42db-870f-bd0e550fc1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start time measurement\n",
    "#start_time = time.time()\n",
    "\n",
    "# Convert the list of embeddings into a numpy array for easier manipulation\n",
    "embeddings = np.array(all_embeddings)\n",
    "\n",
    "# (Optional) \n",
    "#reduced_embeddings = apply_pca(embeddings, n_components=50)\n",
    "\n",
    "# End time measurement\n",
    "#end_time = time.time()\n",
    "\n",
    "# Calculate and print the time taken\n",
    "#time_taken = end_time - start_time\n",
    "#print(f\"⏱️ Tiempo tomado para aplicar PCA a los embeddings: {time_taken:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8eff5209-3c7a-4f8d-9394-bf185be3acac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of existing documents in DB: 0\n",
      "👉 Adding new documents: 1896\n",
      "Adding chunk batch 0.0\n",
      "Adding chunk batch 1.0\n",
      "✅ New documents added successfully\n",
      "⏱️ Tiempo tomado para ingestar los embeddings a ChromaDB: 497.14 seconds\n"
     ]
    }
   ],
   "source": [
    "# Start measuring time for adding the embeddings to ChromaDB\n",
    "start_time = time.time()\n",
    "\n",
    "# Get all existing items in ChromaDB to avoid duplicating data\n",
    "existing_items = db.get(include=[])  # IDs are always included by default\n",
    "existing_ids = set(existing_items[\"ids\"]) # Get the IDs of the existing documents\n",
    "print(f\"Number of existing documents in DB: {len(existing_ids)}\")\n",
    "\n",
    "# Filter out chunks that already exist in the DB by their unique IDs\n",
    "new_chunks = [chunk for chunk in chunks if chunk.metadata[\"id\"] not in existing_ids]\n",
    "new_embeddings = [embeddings[i] for i, chunk in enumerate(chunks) if chunk.metadata[\"id\"] not in existing_ids]\n",
    "\n",
    "# Define a constant batch size for adding documents to ChromaDB\n",
    "BATCH_SIZE = 1000\n",
    "\n",
    "# Try adding new documents and embeddings to ChromaDB in batches\n",
    "try:\n",
    "    if len(new_chunks):\n",
    "        print(f\"👉 Adding new documents: {len(new_chunks)}\")\n",
    "        for start in range(0, len(new_chunks), BATCH_SIZE):\n",
    "            print(f\"Adding chunk batch {start/BATCH_SIZE}\")\n",
    "            batch = new_chunks[start:start + BATCH_SIZE] # Get a batch of chunks\n",
    "            batch_embeddings = new_embeddings[start:start + BATCH_SIZE] # Get corresponding embeddings\n",
    "            batch_ids = [chunk.metadata[\"id\"] for chunk in batch] # Get chunk IDs for the batch\n",
    "            # Add documents and embeddings to ChromaDB\n",
    "            db.add_documents(batch, embeddings=batch_embeddings, ids=batch_ids)\n",
    "        print(\"✅ New documents added successfully\")\n",
    "    else:\n",
    "        print(\"✅ No new documents to add\")\n",
    "except Exception as e:\n",
    "    print(f\"Error occurred during ingestion: {e}\")\n",
    "\n",
    "# End time measurement\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate and print the time taken\n",
    "time_taken = end_time - start_time\n",
    "print(f\"⏱️ Tiempo tomado para ingestar los embeddings a ChromaDB: {time_taken:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97b001d5-a43d-4072-8422-bec10d400533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: Based on the provided references, Fabry disease is a genetic disorder caused by a deficiency of alpha-galactosidase A enzyme. This deficiency leads to the accumulation of globotriaosylsphingosine (lyso-Gb3) in various tissues, causing symptoms such as pain, weakness, and organ damage.\n",
      "\n",
      "One disease that can be related to Fabry disease is Gaucher disease, which is also caused by a deficiency of an enzyme involved in lipid metabolism. In both diseases, the accumulation of abnormal lipids leads to tissue damage and organ dysfunction. Both diseases are characterized by a build-up of sphingolipids, which can cause cellular toxicity and contribute to the development of symptoms.\n",
      "\n",
      "Another example is Tay-Sachs disease, another lysosomal storage disorder caused by a deficiency of hexosaminidase A enzyme. Like Fabry disease, Tay-Sachs disease is characterized by the accumulation of gangliosides in neurons and other tissues, leading to progressive neurological degeneration and death.\n",
      "\n",
      "These similarities highlight the importance of understanding the biochemical pathways involved in lipid metabolism and how disruptions can lead to a range of diseases with similar underlying mechanisms.\n",
      "Sources: ['documents/Medicine.pdf:18:0', 'documents/Medicine.pdf:20:0', 'documents/biomolecules-11-00271.pdf:15:1', 'documents/Medicine.pdf:17:0', 'documents/biomolecules-11-00271.pdf:16:3', 'documents/Medicine.pdf:16:0', 'documents/The DNA sequence of the human X chromosome - PMC.pdf:24:0']\n"
     ]
    }
   ],
   "source": [
    "# Define a prompt template to structure the question and context for LLM\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_community.llms.ollama import Ollama\n",
    "\n",
    "PROMPT_TEMPLATE = \"\"\"\n",
    "Answer the question based only on the following context:\n",
    "\n",
    "{context}\n",
    "\n",
    "---\n",
    "\n",
    "Answer the question based on the above context: {question}\n",
    "\"\"\"\n",
    "# Define the question for the model\n",
    "#question=\"Can you give me some common issues from all diseases you know about?\"\n",
    "#question=\"Do you know how chromosome affects Fabry's disease?\"\n",
    "question=\"How can you relate Fabry disease with any other disease you know about?\"\n",
    "\n",
    "# Perform similarity search on ChromaDB using the question to find relevant chunks\n",
    "results = db.similarity_search_with_score(question, k=7)\n",
    "\n",
    "# Compile the search results into a context for the LLM\n",
    "context_text = \"\\n\\n---\\n\\n\".join([doc.page_content for doc, _score in results])\n",
    "\n",
    "# Prepare the prompt with context and question\n",
    "prompt_template = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)\n",
    "prompt = prompt_template.format(context=context_text, question=question)\n",
    "\n",
    "# Invoke the LLM model to generate an answer based on the context\n",
    "model = Ollama(model=\"llama3\")\n",
    "response_text = model.invoke(prompt)\n",
    "\n",
    "# Extract the sources (document IDs) from the search results\n",
    "sources = [doc.metadata.get(\"id\", None) for doc, _score in results]\n",
    "\n",
    "# Format the final response with the LLM answer and source documents\n",
    "formatted_response = f\"Response: {response_text}\\nSources: {sources}\"\n",
    "\n",
    "# Print the final response along with the sources\n",
    "print(formatted_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a488f3b5-85dc-4832-9091-831ae24bc679",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
